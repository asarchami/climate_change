{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last updated: June 29th 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Climate data exploration: a journey through Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to a demo of Python's data analysis package called `Pandas`. Our goal is to learn about Data Analysis and transformation using Pandas while exploring datasets used to analyze climate change. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The story"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The global goal of this demo is to provide the tools to be able to try and reproduce some of the analysis done in the IPCC global climate reports published in the last decade (see for example https://www.ipcc.ch/pdf/assessment-report/ar5/syr/SYR_AR5_FINAL_full.pdf). \n",
    "\n",
    "We are first going to load a few public datasets containing information about global temperature, global and local sea level infomation, and global concentration of greenhouse gases like CO2, to see if there are correlations and how the trends are to evolve, assuming no fundamental change in the system. For all these datasets, we will download them, visualize them, clean them, search through them, merge them, resample them, transform them and summarize them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the process, we will learn about:\n",
    "\n",
    "Part 1:\n",
    "\n",
    "    1. Loading data\n",
    "    2. Pandas datastructures\n",
    "    3. Cleaning and formatting data\n",
    "    4. Basic visualization\n",
    "   \n",
    "Part 2:\n",
    "\n",
    "    5. Accessing data\n",
    "    6. Working with dates and times\n",
    "    7. Transforming datasets\n",
    "    8. Statistical analysis\n",
    "    9. Data agregation and summarization\n",
    "    10. Correlations and regressions\n",
    "    11. Predictions from auto regression models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 16)\n",
    "\n",
    "LARGE_FIGSIZE = (12, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ali/Dropbox/Projects/pandas_tutorial/climate_timeseries\n",
      "climate_timeseries-Part1.ipynb  climate_timeseries-Part2.ipynb  \u001b[0m\u001b[01;34mdata\u001b[0m/  \u001b[01;34msandbox\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "# Change this cell to the demo location on YOUR machine\n",
    "# %cd ~/Projects/pandas_tutorial/climate_timeseries/\n",
    "%cd ~/Dropbox/Projects/pandas_tutorial/climate_timeseries\n",
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More details, see http://pandas.pydata.org/pandas-docs/stable/io.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find all reading functions in pandas, ask ipython's tab completion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pd.read_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.read_table?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From a local text file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first load some temperature data which covers all lattitudes. Since read_table is supposed to do the job for a text file, let's just try it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1880   -0.1591</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1881   -0.0789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1882   -0.1313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1883   -0.1675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1884   -0.2485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1885   -0.2042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1886   -0.1695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1887   -0.2505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1888   -0.1605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>2003    0.5818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>2004    0.5416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>2005    0.6154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>2006    0.5601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>2007    0.5472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>2008    0.4804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>2009    0.5551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>2010 -999.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1880   -0.1591\n",
       "0    1881   -0.0789\n",
       "1    1882   -0.1313\n",
       "2    1883   -0.1675\n",
       "3    1884   -0.2485\n",
       "4    1885   -0.2042\n",
       "5    1886   -0.1695\n",
       "6    1887   -0.2505\n",
       "7    1888   -0.1605\n",
       "..              ...\n",
       "122  2003    0.5818\n",
       "123  2004    0.5416\n",
       "124  2005    0.6154\n",
       "125  2006    0.5601\n",
       "126  2007    0.5472\n",
       "127  2008    0.4804\n",
       "128  2009    0.5551\n",
       "129  2010 -999.0000\n",
       "\n",
       "[130 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"data/temperatures/annual.land_ocean.90S.90N.df_1901-2000mean.dat\"\n",
    "full_globe_temp = pd.read_table(filename)\n",
    "full_globe_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is only 1 column! Let's try again stating that values are separated by any number of spaces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1880</th>\n",
       "      <th>-0.1591</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1881</td>\n",
       "      <td>-0.0789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1882</td>\n",
       "      <td>-0.1313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1883</td>\n",
       "      <td>-0.1675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1884</td>\n",
       "      <td>-0.2485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1885</td>\n",
       "      <td>-0.2042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1886</td>\n",
       "      <td>-0.1695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1887</td>\n",
       "      <td>-0.2505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1888</td>\n",
       "      <td>-0.1605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>2003</td>\n",
       "      <td>0.5818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>2004</td>\n",
       "      <td>0.5416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>2005</td>\n",
       "      <td>0.6154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>2006</td>\n",
       "      <td>0.5601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>2007</td>\n",
       "      <td>0.5472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>2008</td>\n",
       "      <td>0.4804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>2009</td>\n",
       "      <td>0.5551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>2010</td>\n",
       "      <td>-999.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1880   -0.1591\n",
       "0    1881   -0.0789\n",
       "1    1882   -0.1313\n",
       "2    1883   -0.1675\n",
       "3    1884   -0.2485\n",
       "4    1885   -0.2042\n",
       "5    1886   -0.1695\n",
       "6    1887   -0.2505\n",
       "7    1888   -0.1605\n",
       "..    ...       ...\n",
       "122  2003    0.5818\n",
       "123  2004    0.5416\n",
       "124  2005    0.6154\n",
       "125  2006    0.5601\n",
       "126  2007    0.5472\n",
       "127  2008    0.4804\n",
       "128  2009    0.5551\n",
       "129  2010 -999.0000\n",
       "\n",
       "[130 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_globe_temp = pd.read_table(filename, sep=\"\\s+\")\n",
    "full_globe_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are columns but the column names are 1880 and -0.1591!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>mean temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1880</td>\n",
       "      <td>-0.1591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1881</td>\n",
       "      <td>-0.0789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1882</td>\n",
       "      <td>-0.1313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1883</td>\n",
       "      <td>-0.1675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1884</td>\n",
       "      <td>-0.2485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1885</td>\n",
       "      <td>-0.2042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1886</td>\n",
       "      <td>-0.1695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1887</td>\n",
       "      <td>-0.2505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>2003</td>\n",
       "      <td>0.5818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>2004</td>\n",
       "      <td>0.5416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>2005</td>\n",
       "      <td>0.6154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>2006</td>\n",
       "      <td>0.5601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>2007</td>\n",
       "      <td>0.5472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>2008</td>\n",
       "      <td>0.4804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>2009</td>\n",
       "      <td>0.5551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>2010</td>\n",
       "      <td>-999.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     year  mean temp\n",
       "0    1880    -0.1591\n",
       "1    1881    -0.0789\n",
       "2    1882    -0.1313\n",
       "3    1883    -0.1675\n",
       "4    1884    -0.2485\n",
       "5    1885    -0.2042\n",
       "6    1886    -0.1695\n",
       "7    1887    -0.2505\n",
       "..    ...        ...\n",
       "123  2003     0.5818\n",
       "124  2004     0.5416\n",
       "125  2005     0.6154\n",
       "126  2006     0.5601\n",
       "127  2007     0.5472\n",
       "128  2008     0.4804\n",
       "129  2009     0.5551\n",
       "130  2010  -999.0000\n",
       "\n",
       "[131 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_globe_temp = pd.read_table(filename, sep=\"\\s+\", names=[\"year\", \"mean temp\"])\n",
    "full_globe_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we only have 2 columns, one of which would be nicer to access the data (the year of the record), let's try using the `index_col` option:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean temp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1880</th>\n",
       "      <td>-0.1591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <td>-0.0789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1882</th>\n",
       "      <td>-0.1313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1883</th>\n",
       "      <td>-0.1675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1884</th>\n",
       "      <td>-0.2485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1885</th>\n",
       "      <td>-0.2042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1886</th>\n",
       "      <td>-0.1695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1887</th>\n",
       "      <td>-0.2505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>0.5818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>0.5416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>0.6154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>0.5601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>0.5472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>0.4804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>0.5551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>-999.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean temp\n",
       "year           \n",
       "1880    -0.1591\n",
       "1881    -0.0789\n",
       "1882    -0.1313\n",
       "1883    -0.1675\n",
       "1884    -0.2485\n",
       "1885    -0.2042\n",
       "1886    -0.1695\n",
       "1887    -0.2505\n",
       "...         ...\n",
       "2003     0.5818\n",
       "2004     0.5416\n",
       "2005     0.6154\n",
       "2006     0.5601\n",
       "2007     0.5472\n",
       "2008     0.4804\n",
       "2009     0.5551\n",
       "2010  -999.0000\n",
       "\n",
       "[131 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_globe_temp = pd.read_table(filename, sep=\"\\s+\", names=[\"year\", \"mean temp\"], \n",
    "                                index_col=0)\n",
    "full_globe_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last step: the index is made of dates. Let's make that explicit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean temp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1880-01-01 00:00:00</th>\n",
       "      <td>-0.1591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1881-01-01 00:00:00</th>\n",
       "      <td>-0.0789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1882-01-01 00:00:00</th>\n",
       "      <td>-0.1313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1883-01-01 00:00:00</th>\n",
       "      <td>-0.1675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1884-01-01 00:00:00</th>\n",
       "      <td>-0.2485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1885-01-01 00:00:00</th>\n",
       "      <td>-0.2042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1886-01-01 00:00:00</th>\n",
       "      <td>-0.1695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1887-01-01 00:00:00</th>\n",
       "      <td>-0.2505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-01</th>\n",
       "      <td>0.5818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-01</th>\n",
       "      <td>0.5416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-01</th>\n",
       "      <td>0.6154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-01</th>\n",
       "      <td>0.5601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-01</th>\n",
       "      <td>0.5472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-01</th>\n",
       "      <td>0.4804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01</th>\n",
       "      <td>0.5551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-01</th>\n",
       "      <td>-999.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     mean temp\n",
       "year                          \n",
       "1880-01-01 00:00:00    -0.1591\n",
       "1881-01-01 00:00:00    -0.0789\n",
       "1882-01-01 00:00:00    -0.1313\n",
       "1883-01-01 00:00:00    -0.1675\n",
       "1884-01-01 00:00:00    -0.2485\n",
       "1885-01-01 00:00:00    -0.2042\n",
       "1886-01-01 00:00:00    -0.1695\n",
       "1887-01-01 00:00:00    -0.2505\n",
       "...                        ...\n",
       "2003-01-01              0.5818\n",
       "2004-01-01              0.5416\n",
       "2005-01-01              0.6154\n",
       "2006-01-01              0.5601\n",
       "2007-01-01              0.5472\n",
       "2008-01-01              0.4804\n",
       "2009-01-01              0.5551\n",
       "2010-01-01           -999.0000\n",
       "\n",
       "[131 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_globe_temp = pd.read_table(filename, sep=\"\\s+\", names=[\"year\", \"mean temp\"], \n",
    "                                index_col=0, parse_dates=True)\n",
    "full_globe_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From a chunked file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since every dataset can contain mistakes, let's load a different file with temperature data. NASA's GISS dataset is written in chunks: look at it in `data/temperatures/GLB.Ts+dSST.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Jan</th>\n",
       "      <th>Feb</th>\n",
       "      <th>Mar</th>\n",
       "      <th>Apr</th>\n",
       "      <th>May</th>\n",
       "      <th>Jun</th>\n",
       "      <th>Jul</th>\n",
       "      <th>Aug</th>\n",
       "      <th>Sep</th>\n",
       "      <th>Oct</th>\n",
       "      <th>Nov</th>\n",
       "      <th>Dec</th>\n",
       "      <th>J-D</th>\n",
       "      <th>D-N</th>\n",
       "      <th>DJF</th>\n",
       "      <th>MAM</th>\n",
       "      <th>JJA</th>\n",
       "      <th>SON</th>\n",
       "      <th>Year.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1880</td>\n",
       "      <td>-34</td>\n",
       "      <td>-27</td>\n",
       "      <td>-22</td>\n",
       "      <td>-30</td>\n",
       "      <td>-16</td>\n",
       "      <td>-24</td>\n",
       "      <td>-19</td>\n",
       "      <td>-12</td>\n",
       "      <td>-20</td>\n",
       "      <td>-19</td>\n",
       "      <td>-16</td>\n",
       "      <td>-21</td>\n",
       "      <td>-22</td>\n",
       "      <td>***</td>\n",
       "      <td>****</td>\n",
       "      <td>-23</td>\n",
       "      <td>-18</td>\n",
       "      <td>-18</td>\n",
       "      <td>1880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1881</td>\n",
       "      <td>-13</td>\n",
       "      <td>-16</td>\n",
       "      <td>-2</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-27</td>\n",
       "      <td>-12</td>\n",
       "      <td>-8</td>\n",
       "      <td>-18</td>\n",
       "      <td>-23</td>\n",
       "      <td>-28</td>\n",
       "      <td>-18</td>\n",
       "      <td>-14</td>\n",
       "      <td>-14</td>\n",
       "      <td>-17</td>\n",
       "      <td>-3</td>\n",
       "      <td>-15</td>\n",
       "      <td>-23</td>\n",
       "      <td>1881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1882</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>-2</td>\n",
       "      <td>-24</td>\n",
       "      <td>-20</td>\n",
       "      <td>-32</td>\n",
       "      <td>-27</td>\n",
       "      <td>-11</td>\n",
       "      <td>-11</td>\n",
       "      <td>-25</td>\n",
       "      <td>-25</td>\n",
       "      <td>-37</td>\n",
       "      <td>-17</td>\n",
       "      <td>-16</td>\n",
       "      <td>-4</td>\n",
       "      <td>-15</td>\n",
       "      <td>-23</td>\n",
       "      <td>-20</td>\n",
       "      <td>1882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1883</td>\n",
       "      <td>-38</td>\n",
       "      <td>-38</td>\n",
       "      <td>-12</td>\n",
       "      <td>-20</td>\n",
       "      <td>-20</td>\n",
       "      <td>-8</td>\n",
       "      <td>-3</td>\n",
       "      <td>-13</td>\n",
       "      <td>-19</td>\n",
       "      <td>-19</td>\n",
       "      <td>-28</td>\n",
       "      <td>-21</td>\n",
       "      <td>-20</td>\n",
       "      <td>-21</td>\n",
       "      <td>-38</td>\n",
       "      <td>-18</td>\n",
       "      <td>-8</td>\n",
       "      <td>-22</td>\n",
       "      <td>1883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1884</td>\n",
       "      <td>-20</td>\n",
       "      <td>-14</td>\n",
       "      <td>-31</td>\n",
       "      <td>-36</td>\n",
       "      <td>-33</td>\n",
       "      <td>-36</td>\n",
       "      <td>-31</td>\n",
       "      <td>-24</td>\n",
       "      <td>-29</td>\n",
       "      <td>-25</td>\n",
       "      <td>-29</td>\n",
       "      <td>-25</td>\n",
       "      <td>-28</td>\n",
       "      <td>-28</td>\n",
       "      <td>-18</td>\n",
       "      <td>-33</td>\n",
       "      <td>-31</td>\n",
       "      <td>-28</td>\n",
       "      <td>1884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1885</td>\n",
       "      <td>-57</td>\n",
       "      <td>-29</td>\n",
       "      <td>-19</td>\n",
       "      <td>-36</td>\n",
       "      <td>-35</td>\n",
       "      <td>-40</td>\n",
       "      <td>-28</td>\n",
       "      <td>-24</td>\n",
       "      <td>-17</td>\n",
       "      <td>-14</td>\n",
       "      <td>-14</td>\n",
       "      <td>0</td>\n",
       "      <td>-26</td>\n",
       "      <td>-28</td>\n",
       "      <td>-37</td>\n",
       "      <td>-30</td>\n",
       "      <td>-31</td>\n",
       "      <td>-15</td>\n",
       "      <td>1885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1886</td>\n",
       "      <td>-37</td>\n",
       "      <td>-43</td>\n",
       "      <td>-34</td>\n",
       "      <td>-23</td>\n",
       "      <td>-21</td>\n",
       "      <td>-30</td>\n",
       "      <td>-13</td>\n",
       "      <td>-21</td>\n",
       "      <td>-12</td>\n",
       "      <td>-22</td>\n",
       "      <td>-29</td>\n",
       "      <td>-18</td>\n",
       "      <td>-25</td>\n",
       "      <td>-24</td>\n",
       "      <td>-26</td>\n",
       "      <td>-26</td>\n",
       "      <td>-21</td>\n",
       "      <td>-21</td>\n",
       "      <td>1886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1887</td>\n",
       "      <td>-60</td>\n",
       "      <td>-43</td>\n",
       "      <td>-26</td>\n",
       "      <td>-34</td>\n",
       "      <td>-28</td>\n",
       "      <td>-25</td>\n",
       "      <td>-19</td>\n",
       "      <td>-28</td>\n",
       "      <td>-24</td>\n",
       "      <td>-33</td>\n",
       "      <td>-29</td>\n",
       "      <td>-40</td>\n",
       "      <td>-32</td>\n",
       "      <td>-30</td>\n",
       "      <td>-40</td>\n",
       "      <td>-29</td>\n",
       "      <td>-24</td>\n",
       "      <td>-28</td>\n",
       "      <td>1887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>2009</td>\n",
       "      <td>56</td>\n",
       "      <td>48</td>\n",
       "      <td>49</td>\n",
       "      <td>57</td>\n",
       "      <td>59</td>\n",
       "      <td>62</td>\n",
       "      <td>66</td>\n",
       "      <td>61</td>\n",
       "      <td>64</td>\n",
       "      <td>58</td>\n",
       "      <td>72</td>\n",
       "      <td>58</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>52</td>\n",
       "      <td>55</td>\n",
       "      <td>63</td>\n",
       "      <td>65</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>2010</td>\n",
       "      <td>66</td>\n",
       "      <td>75</td>\n",
       "      <td>87</td>\n",
       "      <td>82</td>\n",
       "      <td>71</td>\n",
       "      <td>60</td>\n",
       "      <td>56</td>\n",
       "      <td>59</td>\n",
       "      <td>55</td>\n",
       "      <td>65</td>\n",
       "      <td>74</td>\n",
       "      <td>44</td>\n",
       "      <td>66</td>\n",
       "      <td>67</td>\n",
       "      <td>66</td>\n",
       "      <td>80</td>\n",
       "      <td>58</td>\n",
       "      <td>65</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>2011</td>\n",
       "      <td>45</td>\n",
       "      <td>44</td>\n",
       "      <td>57</td>\n",
       "      <td>60</td>\n",
       "      <td>47</td>\n",
       "      <td>54</td>\n",
       "      <td>70</td>\n",
       "      <td>69</td>\n",
       "      <td>52</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>48</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>45</td>\n",
       "      <td>55</td>\n",
       "      <td>64</td>\n",
       "      <td>54</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>2012</td>\n",
       "      <td>38</td>\n",
       "      <td>43</td>\n",
       "      <td>52</td>\n",
       "      <td>62</td>\n",
       "      <td>71</td>\n",
       "      <td>59</td>\n",
       "      <td>50</td>\n",
       "      <td>56</td>\n",
       "      <td>68</td>\n",
       "      <td>73</td>\n",
       "      <td>69</td>\n",
       "      <td>46</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>43</td>\n",
       "      <td>62</td>\n",
       "      <td>55</td>\n",
       "      <td>70</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>2013</td>\n",
       "      <td>62</td>\n",
       "      <td>52</td>\n",
       "      <td>60</td>\n",
       "      <td>48</td>\n",
       "      <td>56</td>\n",
       "      <td>61</td>\n",
       "      <td>53</td>\n",
       "      <td>61</td>\n",
       "      <td>73</td>\n",
       "      <td>61</td>\n",
       "      <td>75</td>\n",
       "      <td>61</td>\n",
       "      <td>60</td>\n",
       "      <td>59</td>\n",
       "      <td>53</td>\n",
       "      <td>55</td>\n",
       "      <td>58</td>\n",
       "      <td>70</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>2014</td>\n",
       "      <td>68</td>\n",
       "      <td>44</td>\n",
       "      <td>71</td>\n",
       "      <td>72</td>\n",
       "      <td>79</td>\n",
       "      <td>62</td>\n",
       "      <td>50</td>\n",
       "      <td>74</td>\n",
       "      <td>81</td>\n",
       "      <td>78</td>\n",
       "      <td>64</td>\n",
       "      <td>74</td>\n",
       "      <td>68</td>\n",
       "      <td>67</td>\n",
       "      <td>58</td>\n",
       "      <td>74</td>\n",
       "      <td>62</td>\n",
       "      <td>74</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>2015</td>\n",
       "      <td>75</td>\n",
       "      <td>80</td>\n",
       "      <td>84</td>\n",
       "      <td>71</td>\n",
       "      <td>****</td>\n",
       "      <td>****</td>\n",
       "      <td>****</td>\n",
       "      <td>****</td>\n",
       "      <td>****</td>\n",
       "      <td>****</td>\n",
       "      <td>****</td>\n",
       "      <td>****</td>\n",
       "      <td>****</td>\n",
       "      <td>***</td>\n",
       "      <td>76</td>\n",
       "      <td>****</td>\n",
       "      <td>****</td>\n",
       "      <td>****</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>Year</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Feb</td>\n",
       "      <td>Mar</td>\n",
       "      <td>Apr</td>\n",
       "      <td>May</td>\n",
       "      <td>Jun</td>\n",
       "      <td>Jul</td>\n",
       "      <td>Aug</td>\n",
       "      <td>Sep</td>\n",
       "      <td>Oct</td>\n",
       "      <td>Nov</td>\n",
       "      <td>Dec</td>\n",
       "      <td>J-D</td>\n",
       "      <td>D-N</td>\n",
       "      <td>DJF</td>\n",
       "      <td>MAM</td>\n",
       "      <td>JJA</td>\n",
       "      <td>SON</td>\n",
       "      <td>Year</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year  Jan  Feb  Mar  Apr   May   Jun   Jul   Aug   Sep   Oct   Nov   Dec  \\\n",
       "0    1880  -34  -27  -22  -30   -16   -24   -19   -12   -20   -19   -16   -21   \n",
       "1    1881  -13  -16   -2   -3    -3   -27   -12    -8   -18   -23   -28   -18   \n",
       "2    1882    3    4   -2  -24   -20   -32   -27   -11   -11   -25   -25   -37   \n",
       "3    1883  -38  -38  -12  -20   -20    -8    -3   -13   -19   -19   -28   -21   \n",
       "4    1884  -20  -14  -31  -36   -33   -36   -31   -24   -29   -25   -29   -25   \n",
       "5    1885  -57  -29  -19  -36   -35   -40   -28   -24   -17   -14   -14     0   \n",
       "6    1886  -37  -43  -34  -23   -21   -30   -13   -21   -12   -22   -29   -18   \n",
       "7    1887  -60  -43  -26  -34   -28   -25   -19   -28   -24   -33   -29   -40   \n",
       "..    ...  ...  ...  ...  ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "135  2009   56   48   49   57    59    62    66    61    64    58    72    58   \n",
       "136  2010   66   75   87   82    71    60    56    59    55    65    74    44   \n",
       "137  2011   45   44   57   60    47    54    70    69    52    60    50    48   \n",
       "138  2012   38   43   52   62    71    59    50    56    68    73    69    46   \n",
       "139  2013   62   52   60   48    56    61    53    61    73    61    75    61   \n",
       "140  2014   68   44   71   72    79    62    50    74    81    78    64    74   \n",
       "141  2015   75   80   84   71  ****  ****  ****  ****  ****  ****  ****  ****   \n",
       "142  Year  Jan  Feb  Mar  Apr   May   Jun   Jul   Aug   Sep   Oct   Nov   Dec   \n",
       "\n",
       "      J-D  D-N   DJF   MAM   JJA   SON Year.1  \n",
       "0     -22  ***  ****   -23   -18   -18   1880  \n",
       "1     -14  -14   -17    -3   -15   -23   1881  \n",
       "2     -17  -16    -4   -15   -23   -20   1882  \n",
       "3     -20  -21   -38   -18    -8   -22   1883  \n",
       "4     -28  -28   -18   -33   -31   -28   1884  \n",
       "5     -26  -28   -37   -30   -31   -15   1885  \n",
       "6     -25  -24   -26   -26   -21   -21   1886  \n",
       "7     -32  -30   -40   -29   -24   -28   1887  \n",
       "..    ...  ...   ...   ...   ...   ...    ...  \n",
       "135    59   59    52    55    63    65   2009  \n",
       "136    66   67    66    80    58    65   2010  \n",
       "137    55   55    45    55    64    54   2011  \n",
       "138    57   57    43    62    55    70   2012  \n",
       "139    60   59    53    55    58    70   2013  \n",
       "140    68   67    58    74    62    74   2014  \n",
       "141  ****  ***    76  ****  ****  ****   2015  \n",
       "142   J-D  D-N   DJF   MAM   JJA   SON   Year  \n",
       "\n",
       "[143 rows x 20 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "giss_temp = pd.read_table(\"data/temperatures/GLB.Ts+dSST.txt\", sep=\"\\s+\", skiprows=7,\n",
    "                          skip_footer=11, engine=\"python\")\n",
    "giss_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUIZ:** What happens if you remove the `skiprows`? `skipfooter`? `engine`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE:** Load some readings of CO2 concentrations in the atmosphere from the `data/greenhouse_gaz/co2_mm_global.txt` data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_month</th>\n",
       "      <th>decimal</th>\n",
       "      <th>average</th>\n",
       "      <th>trend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1980-01-01</td>\n",
       "      <td>1980.042</td>\n",
       "      <td>338.45</td>\n",
       "      <td>337.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1980-02-01</td>\n",
       "      <td>1980.125</td>\n",
       "      <td>339.17</td>\n",
       "      <td>338.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1980-03-01</td>\n",
       "      <td>1980.208</td>\n",
       "      <td>339.49</td>\n",
       "      <td>338.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1980-04-01</td>\n",
       "      <td>1980.292</td>\n",
       "      <td>339.87</td>\n",
       "      <td>338.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1980-05-01</td>\n",
       "      <td>1980.375</td>\n",
       "      <td>340.30</td>\n",
       "      <td>338.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1980-06-01</td>\n",
       "      <td>1980.458</td>\n",
       "      <td>339.86</td>\n",
       "      <td>339.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1980-07-01</td>\n",
       "      <td>1980.542</td>\n",
       "      <td>338.32</td>\n",
       "      <td>339.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1980-08-01</td>\n",
       "      <td>1980.625</td>\n",
       "      <td>337.11</td>\n",
       "      <td>339.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>2014-09-01</td>\n",
       "      <td>2014.708</td>\n",
       "      <td>394.90</td>\n",
       "      <td>397.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>2014-10-01</td>\n",
       "      <td>2014.792</td>\n",
       "      <td>396.18</td>\n",
       "      <td>397.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>2014-11-01</td>\n",
       "      <td>2014.875</td>\n",
       "      <td>397.69</td>\n",
       "      <td>397.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>2014-12-01</td>\n",
       "      <td>2014.958</td>\n",
       "      <td>398.62</td>\n",
       "      <td>398.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>2015.042</td>\n",
       "      <td>399.31</td>\n",
       "      <td>398.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>2015-02-01</td>\n",
       "      <td>2015.125</td>\n",
       "      <td>400.01</td>\n",
       "      <td>398.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>2015-03-01</td>\n",
       "      <td>2015.208</td>\n",
       "      <td>400.59</td>\n",
       "      <td>398.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>2015.292</td>\n",
       "      <td>401.24</td>\n",
       "      <td>399.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>424 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    year_month   decimal  average   trend\n",
       "0   1980-01-01  1980.042   338.45  337.82\n",
       "1   1980-02-01  1980.125   339.17  338.12\n",
       "2   1980-03-01  1980.208   339.49  338.14\n",
       "3   1980-04-01  1980.292   339.87  338.25\n",
       "4   1980-05-01  1980.375   340.30  338.78\n",
       "5   1980-06-01  1980.458   339.86  339.08\n",
       "6   1980-07-01  1980.542   338.32  339.17\n",
       "7   1980-08-01  1980.625   337.11  339.37\n",
       "..         ...       ...      ...     ...\n",
       "416 2014-09-01  2014.708   394.90  397.61\n",
       "417 2014-10-01  2014.792   396.18  397.63\n",
       "418 2014-11-01  2014.875   397.69  397.90\n",
       "419 2014-12-01  2014.958   398.62  398.08\n",
       "420 2015-01-01  2015.042   399.31  398.29\n",
       "421 2015-02-01  2015.125   400.01  398.59\n",
       "422 2015-03-01  2015.208   400.59  398.96\n",
       "423 2015-04-01  2015.292   401.24  399.41\n",
       "\n",
       "[424 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "co2_concentration = pd.read_table(\"data/greenhouse_gaz/co2_mm_global.txt\", sep=\"\\s+\", \n",
    "                                  parse_dates = [[0, 1]])\n",
    "# parse two comlums(1 and 2) together inside a column\n",
    "co2_concentration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From a remote text file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have only loaded temperature datasets. Climate change also affects the sea levels on the globe. Let's load some datasets with the sea levels. The university of colorado posts updated timeseries for mean sea level globably, per \n",
    "hemisphere, or even per ocean, sea, ... Let's download the global one, and the ones for the northern and southern hemisphere."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That will also illustrate that to load text files that are online, there is no more work than replacing the filepath by a URL n `read_table`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>msl_ib(mm)</th>\n",
       "      <th>#version_2016_rel4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1992.9323</td>\n",
       "      <td>13.717</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1992.9595</td>\n",
       "      <td>1.328</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1992.9866</td>\n",
       "      <td>-13.375</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1993.0138</td>\n",
       "      <td>-24.723</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1993.0409</td>\n",
       "      <td>-29.231</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1993.0681</td>\n",
       "      <td>-32.538</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1993.0952</td>\n",
       "      <td>-35.588</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1993.1223</td>\n",
       "      <td>-26.579</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>2016.3611</td>\n",
       "      <td>56.282</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>2016.3883</td>\n",
       "      <td>63.273</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>2016.4154</td>\n",
       "      <td>69.371</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>2016.4426</td>\n",
       "      <td>75.595</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>2016.4697</td>\n",
       "      <td>80.087</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>2016.4969</td>\n",
       "      <td>81.619</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>2016.5240</td>\n",
       "      <td>83.580</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>2016.5512</td>\n",
       "      <td>87.190</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>869 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          year  msl_ib(mm)  #version_2016_rel4\n",
       "0    1992.9323      13.717                 NaN\n",
       "1    1992.9595       1.328                 NaN\n",
       "2    1992.9866     -13.375                 NaN\n",
       "3    1993.0138     -24.723                 NaN\n",
       "4    1993.0409     -29.231                 NaN\n",
       "5    1993.0681     -32.538                 NaN\n",
       "6    1993.0952     -35.588                 NaN\n",
       "7    1993.1223     -26.579                 NaN\n",
       "..         ...         ...                 ...\n",
       "861  2016.3611      56.282                 NaN\n",
       "862  2016.3883      63.273                 NaN\n",
       "863  2016.4154      69.371                 NaN\n",
       "864  2016.4426      75.595                 NaN\n",
       "865  2016.4697      80.087                 NaN\n",
       "866  2016.4969      81.619                 NaN\n",
       "867  2016.5240      83.580                 NaN\n",
       "868  2016.5512      87.190                 NaN\n",
       "\n",
       "[869 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Local backup: data/sea_levels/sl_nh.txt\n",
    "northern_sea_level = pd.read_table(\"http://sealevel.colorado.edu/files/current/sl_nh.txt\", \n",
    "                                   sep=\"\\s+\")\n",
    "northern_sea_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>msl_ib(mm)</th>\n",
       "      <th>#version_2016_rel4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1992.9323</td>\n",
       "      <td>2.517</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1992.9595</td>\n",
       "      <td>-7.645</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1992.9866</td>\n",
       "      <td>-2.267</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1993.0138</td>\n",
       "      <td>0.855</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1993.0409</td>\n",
       "      <td>-2.020</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1993.0681</td>\n",
       "      <td>-0.398</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1993.0952</td>\n",
       "      <td>4.102</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1993.1223</td>\n",
       "      <td>6.787</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>2016.3611</td>\n",
       "      <td>66.331</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>2016.3883</td>\n",
       "      <td>64.067</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>2016.4154</td>\n",
       "      <td>68.305</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>2016.4426</td>\n",
       "      <td>67.053</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>2016.4697</td>\n",
       "      <td>65.238</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>2016.4969</td>\n",
       "      <td>54.950</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>2016.5240</td>\n",
       "      <td>53.514</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>2016.5512</td>\n",
       "      <td>55.389</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>869 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          year  msl_ib(mm)  #version_2016_rel4\n",
       "0    1992.9323       2.517                 NaN\n",
       "1    1992.9595      -7.645                 NaN\n",
       "2    1992.9866      -2.267                 NaN\n",
       "3    1993.0138       0.855                 NaN\n",
       "4    1993.0409      -2.020                 NaN\n",
       "5    1993.0681      -0.398                 NaN\n",
       "6    1993.0952       4.102                 NaN\n",
       "7    1993.1223       6.787                 NaN\n",
       "..         ...         ...                 ...\n",
       "861  2016.3611      66.331                 NaN\n",
       "862  2016.3883      64.067                 NaN\n",
       "863  2016.4154      68.305                 NaN\n",
       "864  2016.4426      67.053                 NaN\n",
       "865  2016.4697      65.238                 NaN\n",
       "866  2016.4969      54.950                 NaN\n",
       "867  2016.5240      53.514                 NaN\n",
       "868  2016.5512      55.389                 NaN\n",
       "\n",
       "[869 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Local backup: data/sea_levels/sl_sh.txt\n",
    "southern_sea_level = pd.read_table(\"http://sealevel.colorado.edu/files/current/sl_sh.txt\", \n",
    "                                   sep=\"\\s+\")\n",
    "southern_sea_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>msl_ib_ns(mm)</th>\n",
       "      <th>#version_2015_rel2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1992.9595</td>\n",
       "      <td>-5.818</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1992.9866</td>\n",
       "      <td>-7.525</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1993.0138</td>\n",
       "      <td>-9.215</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1993.0409</td>\n",
       "      <td>-11.796</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1993.0681</td>\n",
       "      <td>-11.291</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1993.0952</td>\n",
       "      <td>-9.569</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1993.1223</td>\n",
       "      <td>-3.714</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1993.1495</td>\n",
       "      <td>-2.471</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>2014.9494</td>\n",
       "      <td>70.723</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>2014.9766</td>\n",
       "      <td>70.522</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>2015.0037</td>\n",
       "      <td>66.662</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>2015.0309</td>\n",
       "      <td>64.804</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>2015.0580</td>\n",
       "      <td>62.115</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>2015.0852</td>\n",
       "      <td>68.589</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>2015.1123</td>\n",
       "      <td>69.745</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>2015.1395</td>\n",
       "      <td>75.007</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>780 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          year  msl_ib_ns(mm)  #version_2015_rel2\n",
       "0    1992.9595         -5.818                 NaN\n",
       "1    1992.9866         -7.525                 NaN\n",
       "2    1993.0138         -9.215                 NaN\n",
       "3    1993.0409        -11.796                 NaN\n",
       "4    1993.0681        -11.291                 NaN\n",
       "5    1993.0952         -9.569                 NaN\n",
       "6    1993.1223         -3.714                 NaN\n",
       "7    1993.1495         -2.471                 NaN\n",
       "..         ...            ...                 ...\n",
       "772  2014.9494         70.723                 NaN\n",
       "773  2014.9766         70.522                 NaN\n",
       "774  2015.0037         66.662                 NaN\n",
       "775  2015.0309         64.804                 NaN\n",
       "776  2015.0580         62.115                 NaN\n",
       "777  2015.0852         68.589                 NaN\n",
       "778  2015.1123         69.745                 NaN\n",
       "779  2015.1395         75.007                 NaN\n",
       "\n",
       "[780 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The 2015 version of the global dataset:\n",
    "# Local backup: data/sea_levels/sl_ns_global.txt\n",
    "url = \"http://sealevel.colorado.edu/files/2015_rel2/sl_ns_global.txt\"\n",
    "global_sea_level = pd.read_table(url, sep=\"\\s+\")\n",
    "global_sea_level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are clearly lots of cleanup to be done on these datasets. See below..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From a local or remote HTML file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to grab more local data about mean sea levels, we can download and extract data about mean sea level stations around the world from the PSMSL (http://www.psmsl.org/). Again to download and parse all tables in a webpage, just give `read_html` the URL to parse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Needs `lxml`, `beautifulSoup4` and `html5lib` python packages\n",
    "# Local backup in data/sea_levels/Obtaining Tide Gauge Data.html\n",
    "table_list = pd.read_html(\"http://www.psmsl.org/data/obtaining/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[                 Station Name    ID    Lat.     Lon.  GLOSS ID   Country    \\\n",
       " 0                    HELIGMAN   231  60.200   19.300         NaN       ALA   \n",
       " 1                KOBBAKLINTAR    63  60.033   19.883         NaN       ALA   \n",
       " 2                    LEMSTROM    84  60.100   20.017         NaN       ALA   \n",
       " 3             FOGLO / DEGERBY   249  60.032   20.385         NaN       ALA   \n",
       " 4                   PAGO PAGO   539 -14.280 -170.690       144.0       ASM   \n",
       " 5             BAHIA ESPERANZA   988 -63.300  -56.917       185.0       ATA   \n",
       " 6           ARGENTINE ISLANDS   913 -65.246  -64.257       188.0       ATA   \n",
       " 7            PUERTO SOBERANIA  1603 -62.483  -59.633       189.0       ATA   \n",
       " ...                       ...   ...     ...      ...         ...       ...   \n",
       " 1462                   DANANG  1475  16.100  108.217         NaN       VNM   \n",
       " 1463                   HONNGU  1003  18.800  105.767         NaN       VNM   \n",
       " 1464                   HONDAU   841  20.667  106.800         NaN       VNM   \n",
       " 1465         CHARLOTTE AMALIE  1393  18.335  -64.920         NaN       VIR   \n",
       " 1466  LIME TREE BAY, ST CROIX  1447  17.693  -64.753         NaN       VIR   \n",
       " 1467    CHRISTIANSTED HARBOUR  2118  17.750  -64.705         NaN       VIR   \n",
       " 1468             LAMESHUR BAY  2119  18.317  -64.723         NaN       VIR   \n",
       " 1469                     ADEN    44  12.788   44.974         3.0       YEM   \n",
       " \n",
       "             Date  Coastline    Station    \n",
       " 0     01/01/1980           60        251  \n",
       " 1     01/01/1980           60        261  \n",
       " 2     01/01/1980           60        271  \n",
       " 3     06/10/2015           60        281  \n",
       " 4     08/03/2016          745          1  \n",
       " 5     11/05/1999          999          1  \n",
       " 6     21/05/2015          999          3  \n",
       " 7     30/09/2004          999          5  \n",
       " ...          ...          ...        ...  \n",
       " 1462  17/11/2015          605         51  \n",
       " 1463  17/11/2015          605         61  \n",
       " 1464  17/11/2015          605         81  \n",
       " 1465  08/03/2016          939          1  \n",
       " 1466  08/03/2016          939         11  \n",
       " 1467  09/03/2016          939         15  \n",
       " 1468  09/03/2016          939         21  \n",
       " 1469  01/02/2016          485          1  \n",
       " \n",
       " [1470 rows x 9 columns]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station Name</th>\n",
       "      <th>ID</th>\n",
       "      <th>Lat.</th>\n",
       "      <th>Lon.</th>\n",
       "      <th>GLOSS ID</th>\n",
       "      <th>Country</th>\n",
       "      <th>Date</th>\n",
       "      <th>Coastline</th>\n",
       "      <th>Station</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HELIGMAN</td>\n",
       "      <td>231</td>\n",
       "      <td>60.200</td>\n",
       "      <td>19.300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ALA</td>\n",
       "      <td>01/01/1980</td>\n",
       "      <td>60</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KOBBAKLINTAR</td>\n",
       "      <td>63</td>\n",
       "      <td>60.033</td>\n",
       "      <td>19.883</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ALA</td>\n",
       "      <td>01/01/1980</td>\n",
       "      <td>60</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LEMSTROM</td>\n",
       "      <td>84</td>\n",
       "      <td>60.100</td>\n",
       "      <td>20.017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ALA</td>\n",
       "      <td>01/01/1980</td>\n",
       "      <td>60</td>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FOGLO / DEGERBY</td>\n",
       "      <td>249</td>\n",
       "      <td>60.032</td>\n",
       "      <td>20.385</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ALA</td>\n",
       "      <td>06/10/2015</td>\n",
       "      <td>60</td>\n",
       "      <td>281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PAGO PAGO</td>\n",
       "      <td>539</td>\n",
       "      <td>-14.280</td>\n",
       "      <td>-170.690</td>\n",
       "      <td>144.0</td>\n",
       "      <td>ASM</td>\n",
       "      <td>08/03/2016</td>\n",
       "      <td>745</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BAHIA ESPERANZA</td>\n",
       "      <td>988</td>\n",
       "      <td>-63.300</td>\n",
       "      <td>-56.917</td>\n",
       "      <td>185.0</td>\n",
       "      <td>ATA</td>\n",
       "      <td>11/05/1999</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ARGENTINE ISLANDS</td>\n",
       "      <td>913</td>\n",
       "      <td>-65.246</td>\n",
       "      <td>-64.257</td>\n",
       "      <td>188.0</td>\n",
       "      <td>ATA</td>\n",
       "      <td>21/05/2015</td>\n",
       "      <td>999</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PUERTO SOBERANIA</td>\n",
       "      <td>1603</td>\n",
       "      <td>-62.483</td>\n",
       "      <td>-59.633</td>\n",
       "      <td>189.0</td>\n",
       "      <td>ATA</td>\n",
       "      <td>30/09/2004</td>\n",
       "      <td>999</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1462</th>\n",
       "      <td>DANANG</td>\n",
       "      <td>1475</td>\n",
       "      <td>16.100</td>\n",
       "      <td>108.217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VNM</td>\n",
       "      <td>17/11/2015</td>\n",
       "      <td>605</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463</th>\n",
       "      <td>HONNGU</td>\n",
       "      <td>1003</td>\n",
       "      <td>18.800</td>\n",
       "      <td>105.767</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VNM</td>\n",
       "      <td>17/11/2015</td>\n",
       "      <td>605</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1464</th>\n",
       "      <td>HONDAU</td>\n",
       "      <td>841</td>\n",
       "      <td>20.667</td>\n",
       "      <td>106.800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VNM</td>\n",
       "      <td>17/11/2015</td>\n",
       "      <td>605</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>CHARLOTTE AMALIE</td>\n",
       "      <td>1393</td>\n",
       "      <td>18.335</td>\n",
       "      <td>-64.920</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VIR</td>\n",
       "      <td>08/03/2016</td>\n",
       "      <td>939</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>LIME TREE BAY, ST CROIX</td>\n",
       "      <td>1447</td>\n",
       "      <td>17.693</td>\n",
       "      <td>-64.753</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VIR</td>\n",
       "      <td>08/03/2016</td>\n",
       "      <td>939</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>CHRISTIANSTED HARBOUR</td>\n",
       "      <td>2118</td>\n",
       "      <td>17.750</td>\n",
       "      <td>-64.705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VIR</td>\n",
       "      <td>09/03/2016</td>\n",
       "      <td>939</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>LAMESHUR BAY</td>\n",
       "      <td>2119</td>\n",
       "      <td>18.317</td>\n",
       "      <td>-64.723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VIR</td>\n",
       "      <td>09/03/2016</td>\n",
       "      <td>939</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>ADEN</td>\n",
       "      <td>44</td>\n",
       "      <td>12.788</td>\n",
       "      <td>44.974</td>\n",
       "      <td>3.0</td>\n",
       "      <td>YEM</td>\n",
       "      <td>01/02/2016</td>\n",
       "      <td>485</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1470 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Station Name    ID    Lat.     Lon.  GLOSS ID   Country    \\\n",
       "0                    HELIGMAN   231  60.200   19.300         NaN       ALA   \n",
       "1                KOBBAKLINTAR    63  60.033   19.883         NaN       ALA   \n",
       "2                    LEMSTROM    84  60.100   20.017         NaN       ALA   \n",
       "3             FOGLO / DEGERBY   249  60.032   20.385         NaN       ALA   \n",
       "4                   PAGO PAGO   539 -14.280 -170.690       144.0       ASM   \n",
       "5             BAHIA ESPERANZA   988 -63.300  -56.917       185.0       ATA   \n",
       "6           ARGENTINE ISLANDS   913 -65.246  -64.257       188.0       ATA   \n",
       "7            PUERTO SOBERANIA  1603 -62.483  -59.633       189.0       ATA   \n",
       "...                       ...   ...     ...      ...         ...       ...   \n",
       "1462                   DANANG  1475  16.100  108.217         NaN       VNM   \n",
       "1463                   HONNGU  1003  18.800  105.767         NaN       VNM   \n",
       "1464                   HONDAU   841  20.667  106.800         NaN       VNM   \n",
       "1465         CHARLOTTE AMALIE  1393  18.335  -64.920         NaN       VIR   \n",
       "1466  LIME TREE BAY, ST CROIX  1447  17.693  -64.753         NaN       VIR   \n",
       "1467    CHRISTIANSTED HARBOUR  2118  17.750  -64.705         NaN       VIR   \n",
       "1468             LAMESHUR BAY  2119  18.317  -64.723         NaN       VIR   \n",
       "1469                     ADEN    44  12.788   44.974         3.0       YEM   \n",
       "\n",
       "            Date  Coastline    Station    \n",
       "0     01/01/1980           60        251  \n",
       "1     01/01/1980           60        261  \n",
       "2     01/01/1980           60        271  \n",
       "3     06/10/2015           60        281  \n",
       "4     08/03/2016          745          1  \n",
       "5     11/05/1999          999          1  \n",
       "6     21/05/2015          999          3  \n",
       "7     30/09/2004          999          5  \n",
       "...          ...          ...        ...  \n",
       "1462  17/11/2015          605         51  \n",
       "1463  17/11/2015          605         61  \n",
       "1464  17/11/2015          605         81  \n",
       "1465  08/03/2016          939          1  \n",
       "1466  08/03/2016          939         11  \n",
       "1467  09/03/2016          939         15  \n",
       "1468  09/03/2016          939         21  \n",
       "1469  01/02/2016          485          1  \n",
       "\n",
       "[1470 rows x 9 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there is 1 table on that page which contains metadata about the stations where \n",
    "# sea levels are recorded\n",
    "local_sea_level_stations = table_list[0]\n",
    "local_sea_level_stations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That table can be used to search for a station in a region of the world we choose, extract an ID for it and download the corresponding time series with the URL http://www.psmsl.org/data/obtaining/met.monthly.data/< ID >.metdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pandas DataStructures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more details, see http://pandas.pydata.org/pandas-docs/stable/dsintro.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have used `read_**` functions to load datasets, we need to understand better what kind of objects we got from them to learn to work with them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame, the pandas 2D structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Type of the object?\n",
    "type(giss_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(143, 20)\n",
      "Year      object\n",
      "Jan       object\n",
      "Feb       object\n",
      "Mar       object\n",
      "Apr       object\n",
      "May       object\n",
      "Jun       object\n",
      "Jul       object\n",
      "           ...  \n",
      "Dec       object\n",
      "J-D       object\n",
      "D-N       object\n",
      "DJF       object\n",
      "MAM       object\n",
      "JJA       object\n",
      "SON       object\n",
      "Year.1    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Internal nature of the object\n",
    "print(giss_temp.shape)\n",
    "print(giss_temp.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descriptors for the vertical axis (axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=143, step=1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "giss_temp.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descriptors for the horizontal axis (axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Year', u'Jan', u'Feb', u'Mar', u'Apr', u'May', u'Jun', u'Jul', u'Aug',\n",
       "       u'Sep', u'Oct', u'Nov', u'Dec', u'J-D', u'D-N', u'DJF', u'MAM', u'JJA',\n",
       "       u'SON', u'Year.1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "giss_temp.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of information at once including memory usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 143 entries, 0 to 142\n",
      "Data columns (total 20 columns):\n",
      "Year      143 non-null object\n",
      "Jan       143 non-null object\n",
      "Feb       143 non-null object\n",
      "Mar       143 non-null object\n",
      "Apr       143 non-null object\n",
      "May       143 non-null object\n",
      "Jun       143 non-null object\n",
      "Jul       143 non-null object\n",
      "Aug       143 non-null object\n",
      "Sep       143 non-null object\n",
      "Oct       143 non-null object\n",
      "Nov       143 non-null object\n",
      "Dec       143 non-null object\n",
      "J-D       143 non-null object\n",
      "D-N       143 non-null object\n",
      "DJF       143 non-null object\n",
      "MAM       143 non-null object\n",
      "JJA       143 non-null object\n",
      "SON       143 non-null object\n",
      "Year.1    143 non-null object\n",
      "dtypes: object(20)\n",
      "memory usage: 22.4+ KB\n"
     ]
    }
   ],
   "source": [
    "giss_temp.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series, the pandas 1D structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A series can be constructed with the `pd.Series` constructor (passing a list or array of values) or from a `DataFrame`, by extracting one of its columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do we already have a series for the full_globe_temp?\n",
    "type(full_globe_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year\n",
       "1880-01-01 00:00:00     -0.1591\n",
       "1881-01-01 00:00:00     -0.0789\n",
       "1882-01-01 00:00:00     -0.1313\n",
       "1883-01-01 00:00:00     -0.1675\n",
       "1884-01-01 00:00:00     -0.2485\n",
       "1885-01-01 00:00:00     -0.2042\n",
       "1886-01-01 00:00:00     -0.1695\n",
       "1887-01-01 00:00:00     -0.2505\n",
       "                         ...   \n",
       "2003-01-01               0.5818\n",
       "2004-01-01               0.5416\n",
       "2005-01-01               0.6154\n",
       "2006-01-01               0.5601\n",
       "2007-01-01               0.5472\n",
       "2008-01-01               0.4804\n",
       "2009-01-01               0.5551\n",
       "2010-01-01            -999.0000\n",
       "Name: mean temp, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_globe_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'mean temp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-ca60b089cde4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Since there is only one column of values, we can make this a Series without\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# loosing information:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfull_globe_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_globe_temp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mean temp\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ali/anaconda2/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ali/anaconda2/lib/python2.7/site-packages/pandas/tseries/index.pyc\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   1392\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value_maybe_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1393\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1394\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1396\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_value_maybe_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'mean temp'"
     ]
    }
   ],
   "source": [
    "# Since there is only one column of values, we can make this a Series without \n",
    "# loosing information:\n",
    "full_globe_temp = full_globe_temp[\"mean temp\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Core attributes/information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(type(full_globe_temp))\n",
    "print(full_globe_temp.dtype)\n",
    "print(full_globe_temp.shape)\n",
    "print(full_globe_temp.nbytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probably the most important attribute of a `Series` or `DataFrame` is its `index` since we will use that to, well, index into the structures to access te information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_globe_temp.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy arrays as backend of Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is always possible to fall back to a good old NumPy array to pass on to scientific libraries that need them: SciPy, scikit-learn, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_globe_temp.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(full_globe_temp.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating new DataFrames manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame`s can also be created manually, by grouping several Series together. Let's make a new frame from the 3 sea level datasets we downloaded above. They will be displayed along the same index. Wait, does that makes sense to do that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Are they aligned?\n",
    "southern_sea_level.year == northern_sea_level.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# So, are they aligned?\n",
    "np.all(southern_sea_level.year == northern_sea_level.year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the northern hemisphere and southern hemisphere datasets are aligned. What about the global one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(global_sea_level.year) == len(northern_sea_level.year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, let's just build a DataFrame with the 2 hemisphere datasets then. We will come back to add the global one later..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_sea_level = pd.DataFrame({\"northern_hem\": northern_sea_level[\"msl_ib(mm)\"], \n",
    "                               \"southern_hem\": southern_sea_level[\"msl_ib(mm)\"], \n",
    "                               \"date\": northern_sea_level.year})\n",
    "mean_sea_level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: there are other ways to create DataFrames manually, for example from a 2D numpy array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is still the date in a regular column and a numerical index that is not that meaningful. We can specify the `index` of a `DataFrame` at creation. Let's try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_sea_level = pd.DataFrame({\"northern_hem\": northern_sea_level[\"msl_ib(mm)\"], \n",
    "                               \"southern_hem\": southern_sea_level[\"msl_ib(mm)\"]},\n",
    "                               index = northern_sea_level.year)\n",
    "mean_sea_level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the fact that it is failing show that Pandas does auto-alignment of values: for each value of the index, it searches for a value in each Series that maps the same value. Since these series have a dumb numerical index, no values are found. \n",
    "\n",
    "Since we know that the order of the values match the index we chose, we can replace the Series by their values only at creation of the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_sea_level = pd.DataFrame({\"northern_hem\": northern_sea_level[\"msl_ib(mm)\"].values, \n",
    "                               \"southern_hem\": southern_sea_level[\"msl_ib(mm)\"].values},\n",
    "                               index = northern_sea_level.year)\n",
    "mean_sea_level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cleaning and formatting data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datasets that we obtain straight from the reading functions are pretty raw. A lot of pre-processing can be done during data read but we haven't used all the power of the reading functions. Let's learn to do a lot of cleaning and formatting of the data.\n",
    "\n",
    "The GISS temperature dataset has a lot of issues too: useless numerical index, redundant columns, useless rows, placeholder (`****`) for missing values, and wrong type for the columns. Let's fix all this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The columns of the local_sea_level_stations aren't clean: they contain spaces and dots.\n",
    "local_sea_level_stations.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's clean them up a bit:\n",
    "local_sea_level_stations.columns = [name.strip().replace(\".\", \"\") \n",
    "                                    for name in local_sea_level_stations.columns]\n",
    "local_sea_level_stations.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also rename an index by setting its name. For example, the index of the `mean_sea_level` dataFrame could be called `date` since it contains more than just the year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_sea_level.index.name = \"date\"\n",
    "mean_sea_level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the full globe dataset, -999.00 was used to indicate that there was no value for that year. Let's search for all these values and replace them with the missing value that Pandas understand: `np.nan` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_globe_temp == -999.000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_globe_temp[full_globe_temp == -999.000] = np.nan\n",
    "full_globe_temp.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing what is the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We didn't set a column number of the index of giss_temp, we can do that afterwards:\n",
    "giss_temp = giss_temp.set_index(\"Year\")\n",
    "giss_temp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1 column is redundant with the index: \n",
    "giss_temp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's drop it:\n",
    "giss_temp = giss_temp.drop(\"Year.1\", axis=1)\n",
    "giss_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We can also just select the columns we want to keep:\n",
    "giss_temp = giss_temp[[u'Jan', u'Feb', u'Mar', u'Apr', u'May', u'Jun', u'Jul', \n",
    "                       u'Aug', u'Sep', u'Oct', u'Nov', u'Dec']]\n",
    "giss_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's remove all these extra column names (Year  Jan ...). They all correspond to the index \"Year\"\n",
    "giss_temp = giss_temp.drop(\"Year\")\n",
    "giss_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also set `****` to a real missing value (`np.nan`). We can often do it using a boolean mask, but that may trigger pandas warning. Another way to assign based on a boolean condition is to use the `where` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#giss_temp[giss_temp == \"****\"] = np.nan\n",
    "giss_temp = giss_temp.where(giss_temp != \"****\", np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "giss_temp.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While building the `mean_sea_level` dataFrame earlier, we didn't include the values from `global_sea_level` since the years were not aligned. Adding a column to a dataframe is as easy as adding an entry to a dictionary. So let's try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_sea_level[\"mean_global\"] = global_sea_level[\"msl_ib_ns(mm)\"]\n",
    "mean_sea_level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column is full of NaNs again because the auto-alignment feature of Pandas is searching for the index values like `1992.9323` in the index of `global_sea_level[\"msl_ib_ns(mm)\"]` series and not finding them. Let's set its index to these years so that that auto-alignment can work for us and figure out which values we have and not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "global_sea_level = global_sea_level.set_index(\"year\")\n",
    "global_sea_level[\"msl_ib_ns(mm)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_sea_level[\"mean_global\"] = global_sea_level[\"msl_ib_ns(mm)\"]\n",
    "mean_sea_level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE:** Create a new series containing the average of the 2 hemispheres minus the global value to see if that is close to 0. Work inside the mean_sea_level dataframe first. Then try with the original Series to see what happens with data alignment while doing computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing dtype of series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the sea levels are looking pretty good, let's got back to the GISS temperature dataset. Because of the labels (strings) found in the middle of the timeseries, every column only assumed to contain strings (didn't convert them to floating point values):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "giss_temp.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That can be changed after the fact (and after the cleanup) with the `astype` method of a `Series`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "giss_temp[\"Jan\"].astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col in giss_temp.columns:\n",
    "    giss_temp.loc[:, col] = giss_temp[col].astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An index has a `dtype` just like any Series and that can be changed after the fact too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "giss_temp.index.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, let's change it to an integer so that values can at least be compared properly. We will learn below to change it to a datetime object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "giss_temp.index = giss_temp.index.astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing missing values - once they have been converted to `np.nan` - is very easy. Entries that contain missing values can be removed (dropped), or filled with many strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_globe_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_globe_temp.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This will remove any year that has a missing value. Use how='all' to keep partial years\n",
    "giss_temp.dropna(how=\"any\").tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "giss_temp.fillna(value=0).tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This fills them with the previous year. See also temp3.interpolate\n",
    "giss_temp.fillna(method=\"ffill\").tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also mention the `.interpolate` method on a `Series`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "giss_temp.Aug.interpolate().tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, we will leave the missing values in all our datasets, because it wouldn't be meaningful to fill them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE:** Go back to the reading functions, and learn more about other options that could have allowed us to fold some of these pre-processing steps into the data loading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Basic visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now they have been formatted, visualizing your datasets is the next logical step and is trivial with Pandas. The first thing to try is to invoke the `.plot` to generate a basic visualization (uses matplotlib under the covers)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Line plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_globe_temp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "giss_temp.plot(figsize=LARGE_FIGSIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_sea_level.plot(subplots=True, figsize=(16, 12));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showing distributions information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Distributions of mean sean level globally and per hemisphere?\n",
    "mean_sea_level.plot(kind=\"kde\", figsize=(12, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUIZ:** How to list the possible kinds of plots that the plot method can allow?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Distributions of temperature in each month since 1880\n",
    "giss_temp.boxplot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are more plot options inside `pandas.tools.plotting`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Is there correlations between the northern and southern sea level timeseries we loaded?\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "scatter_matrix(mean_sea_level, figsize=LARGE_FIGSIZE);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will confirm the correlations we think we see further down..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Storing our work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each `read_**` function to load data, there is a `to_**` method attached to Series and DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE**: explore how the to_csv method work using `ipython`'s ? and store the `giss_temp` dataframe. Do the same to store the full_globe_temp series to another file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another file format that is commonly used is Excel, and there multiple datasets can be stored in 1 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(\"test.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "giss_temp.to_excel(writer, sheet_name=\"GISS temp data\")\n",
    "full_globe_temp.to_excel(writer, sheet_name=\"NASA temp data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(\"test.xls\") as writer:\n",
    "    giss_temp.to_excel(writer, sheet_name=\"GISS temp data\")\n",
    "    pd.DataFrame({\"Full Globe Temp\": full_globe_temp}).to_excel(writer, sheet_name=\"FullGlobe temp data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another, more powerful file format to store binary data, which allows us to store both `Series` and `DataFrame`s without having to cast anybody is HDF5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with pd.HDFStore(\"all_data.h5\") as writer:\n",
    "    giss_temp.to_hdf(writer, \"/temperatures/giss\")\n",
    "    full_globe_temp.to_hdf(writer, \"/temperatures/full_globe\")\n",
    "    mean_sea_level.to_hdf(writer, \"/sea_level/mean_sea_level\")\n",
    "    local_sea_level_stations.to_hdf(writer, \"/sea_level/stations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE**: Add the greenhouse gas dataset in this data store. Store it in a separate folder."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
